{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster\n",
    "This notebook is my solution to the introductory machine learning challenge on kaggle.com. It is meant to highlight the methods I have used and clarify the reasoning behind my choices while building my models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the libraries, loading the data and joining the test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('test.csv')\n",
    "train_set = pd.read_csv('train.csv')\n",
    "all_df = pd.concat((train_set.drop(columns = 'Survived'), test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "The first thing that needs to be done is to check the data for any missing values. The function below presents this information for each of the features in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Number  Percentage\n",
      "Cabin          1014       77.46\n",
      "Age             263       20.09\n",
      "Embarked          2        0.15\n",
      "Fare              1        0.08\n",
      "Ticket            0        0.00\n",
      "Parch             0        0.00\n",
      "SibSp             0        0.00\n",
      "Sex               0        0.00\n",
      "Name              0        0.00\n",
      "Pclass            0        0.00\n",
      "PassengerId       0        0.00\n"
     ]
    }
   ],
   "source": [
    "def compute_nan_stats(df):\n",
    "    numberOfNaN = df.isnull().sum().sort_values(ascending = False)\n",
    "    percentage = round((numberOfNaN/len(df))*100, 2)\n",
    "    return pd.concat([numberOfNaN, percentage], axis = 1, keys = ['Number', 'Percentage'])\n",
    "\n",
    "print(compute_nan_stats(all_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four features with missing values: Cabin, Age, Embarked and Fare. Cabin is missing most of its data, so we will discard it. We have to deal with the other three. Since Embarked is missing only 2 passengers, we can set the embarked value to the port which is the most common. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1307\n",
       "unique       3\n",
       "top          S\n",
       "freq       914\n",
       "Name: Embarked, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df['Embarked'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['Embarked'] = all_df['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing fare can be imputed by using the median fare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.fillna(value = all_df['Fare'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing age values need to be imputed as they are likely to have an impact on the rate of survival. The function below accomplishes this by imputing random age values drawn from a normal distribution with the mean and standard deviation of age of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_age(df):\n",
    "    # We use the train_set statistics for both the train and test sets\n",
    "    mean_age = df.groupby('Pclass')['Age'].mean()\n",
    "    std_age = df.groupby('Pclass')['Age'].std()\n",
    "    agelist = []\n",
    "    for i, passenger in df.iterrows():\n",
    "        if math.isnan(passenger['Age']):\n",
    "            age = round(std_age[passenger['Pclass']] * np.random.randn() + \n",
    "                        mean_age[passenger['Pclass']],1)\n",
    "        else:\n",
    "            age = passenger['Age']\n",
    "        agelist.append(age)\n",
    "    return agelist\n",
    "\n",
    "all_df['Age'] = fill_age(all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of individuals contain information about their social class. We can use this data after extracting this information and categorizing it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mme', 'Jonkheer', 'Master', 'Miss', 'Major', 'the Countess', 'Mrs', 'Mlle', 'Capt', 'Dona', 'Lady', 'Col', 'Rev', 'Don', 'Mr', 'Sir', 'Dr', 'Ms'}\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "for name in all_df['Name']:\n",
    "    titles.append(name.split(',')[1].split('.')[0].strip())\n",
    "title_set = set(titles)\n",
    "all_df['Title'] = titles\n",
    "print(title_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simplify the titles listed above into three categories - ship staff, \n",
    "nobility and commoners - and map each individuals titles into these categories as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_map = {'Col': 'Staff', 'Mlle': 'Commoner', 'Ms': 'Commoner', \n",
    "             'Miss': 'Commoner', 'Lady' : 'Nobility', 'Mr': 'Commoner', \n",
    "             'Mrs': 'Commoner', 'Rev': 'Staff', 'Dona': 'Nobility',\n",
    "             'Capt': 'Staff', 'Sir': 'Nobility', 'the Countess': 'Nobility',\n",
    "             'Major': 'Staff', 'Mme': 'Commoner', 'Dr': 'Staff', \n",
    "             'Don': 'Nobility', 'Master' : 'Commoner', 'Jonkheer': 'Nobility'} \n",
    "\n",
    "# Map titles into social class and replace them with dummy variables\n",
    "all_df['Social Status'] = pd.Series(all_df.Title.map(title_map))\n",
    "# Check if there are any missing values\n",
    "all_df['Social Status'] .isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features SibSp and Parch give the total family size when combined, so we create a new feature FamSize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['FamSize'] = all_df['SibSp'] + all_df['Parch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All missing data are now filled and new features are added. All that is left to do in terms of feature engineering is removing unnecessary features and converting categorical variables to numerical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Social Status</th>\n",
       "      <th>FamSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Commoner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Commoner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Commoner</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Commoner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Commoner</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare    Cabin Embarked  \\\n",
       "0    male  22.0      1      0         A/5 21171   7.2500  14.4542        S   \n",
       "1  female  38.0      1      0          PC 17599  71.2833      C85        C   \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250  14.4542        S   \n",
       "3  female  35.0      1      0            113803  53.1000     C123        S   \n",
       "4    male  35.0      0      0            373450   8.0500  14.4542        S   \n",
       "\n",
       "  Title Social Status  FamSize  \n",
       "0    Mr      Commoner        1  \n",
       "1   Mrs      Commoner        1  \n",
       "2  Miss      Commoner        0  \n",
       "3   Mrs      Commoner        1  \n",
       "4    Mr      Commoner        0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head() # View the dataset as to not make any errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Social Status</th>\n",
       "      <th>FamSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Commoner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Commoner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Commoner</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Commoner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Commoner</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age     Fare Embarked Social Status  FamSize\n",
       "0       3    male  22.0   7.2500        S      Commoner        1\n",
       "1       1  female  38.0  71.2833        C      Commoner        1\n",
       "2       3  female  26.0   7.9250        S      Commoner        0\n",
       "3       1  female  35.0  53.1000        S      Commoner        1\n",
       "4       3    male  35.0   8.0500        S      Commoner        0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.drop(columns = ['PassengerId', 'Name', 'Ticket', 'SibSp', 'Parch', \n",
    "                       'Cabin', 'Title'], inplace = True)\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with categorical variables\n",
    "To accomplish this, both one-hot encoding and label encoding methods will be used. One-hot encoding will be employed for the Embarked feature, since this feature is non-binary and has no hiearchy structure within it that can be used to logically give values to each category. \n",
    "Label encoding will be used for the Sex and Social Status features, since the Sex feature is binary and Social Status has an internal hiearachy (Nobility > Staff > Commoners)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 9 columns):\n",
      "Pclass           1309 non-null int64\n",
      "Sex              1309 non-null int64\n",
      "Age              1309 non-null float64\n",
      "Fare             1309 non-null float64\n",
      "Social Status    1309 non-null int64\n",
      "FamSize          1309 non-null int64\n",
      "Embarked_C       1309 non-null uint8\n",
      "Embarked_Q       1309 non-null uint8\n",
      "Embarked_S       1309 non-null uint8\n",
      "dtypes: float64(2), int64(4), uint8(3)\n",
      "memory usage: 75.4 KB\n"
     ]
    }
   ],
   "source": [
    "all_df['Sex'] = all_df['Sex'].map({'male': 0, 'female': 1}) \n",
    "all_df['Social Status'] = all_df['Social Status'].map({'Commoner': 0, \n",
    "                                                       'Staff': 1,\n",
    "                                                       'Nobility': 2}) \n",
    "ready_data = pd.get_dummies(all_df)\n",
    "ready_data.info() # Check to see everything is in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the data into test and train sets once again \n",
    "X_train = ready_data[:891]\n",
    "Y_train = train_set[\"Survived\"]\n",
    "X_test = ready_data[891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is now ready for classification algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "Several methods will be used to model the system and predict the survival rate of the passengers. The models will be tested using a cross-validation metric with 10 folds. Parameters for some models will be identified using sklearn's gridsearchcv method. The function below will be used to present relevant information from grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_results(grid_search_model):\n",
    "    df = pd.DataFrame.from_dict(grid_search_model.cv_results_['params'])\n",
    "    df['mean_test_score'] = grid_search_model.cv_results_['mean_test_score']\n",
    "    df['rank_test_score'] = grid_search_model.cv_results_['rank_test_score']\n",
    "    print(df)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_accuracy = pd.Series() # Average cross-validation score of each method\n",
    "predictions = pd.DataFrame() # Predictions of each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "acc = cross_val_score(model, X_train, Y_train, cv = 10)\n",
    "cv_accuracy['Logistic Regression'] = acc.mean() * 100\n",
    "predictions['Logistic Regression'] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X_train, Y_train)\n",
    "acc = cross_val_score(model, X_train, Y_train, cv = 10)\n",
    "cv_accuracy['Gaussian Naive Bayes'] = acc.mean() * 100\n",
    "predictions['Gaussian Naive Bayes'] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 3: Linear Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(dual = False)\n",
    "model.fit(X_train, Y_train)\n",
    "acc = cross_val_score(model, X_train, Y_train, cv = 10)\n",
    "cv_accuracy['Linear SVC'] = acc.mean() * 100\n",
    "predictions['Linear SVC'] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 4: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "acc = cross_val_score(model, X_train, Y_train, cv = 10)\n",
    "cv_accuracy['Decision Tree'] = acc.mean() * 100\n",
    "predictions['Decision Tree'] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 5: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_estimators  mean_test_score  rank_test_score\n",
      "0             5         0.787879                9\n",
      "1            10         0.796857                8\n",
      "2            20         0.815937                2\n",
      "3            30         0.809203                5\n",
      "4            40         0.805836                7\n",
      "5            50         0.810325                4\n",
      "6           100         0.817059                1\n",
      "7           150         0.806958                6\n",
      "8           200         0.813692                3\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "parameters = {'n_estimators': [5, 10, 20, 30, 40, 50, 100, 150, 200]}\n",
    "grid_search = GridSearchCV(model, parameters, cv=10)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "# View grid search results\n",
    "df = grid_search_results(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction and cv score\n",
    "cv_accuracy['Random Forest'] = df['mean_test_score'].max() * 100\n",
    "predictions['Random Forest'] = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 6: Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    learning_rate  n_estimators  mean_test_score  rank_test_score\n",
      "0            0.10           100         0.824916               16\n",
      "1            0.10           150         0.831650                3\n",
      "2            0.10           200         0.837262                1\n",
      "3            0.10           250         0.829405                7\n",
      "4            0.10           300         0.828283               11\n",
      "5            0.15           100         0.831650                3\n",
      "6            0.15           150         0.833895                2\n",
      "7            0.15           200         0.827160               13\n",
      "8            0.15           250         0.829405                7\n",
      "9            0.15           300         0.827160               13\n",
      "10           0.20           100         0.829405                7\n",
      "11           0.20           150         0.830527                5\n",
      "12           0.20           200         0.828283               11\n",
      "13           0.20           250         0.827160               13\n",
      "14           0.20           300         0.819304               17\n",
      "15           0.25           100         0.830527                5\n",
      "16           0.25           150         0.829405                7\n",
      "17           0.25           200         0.817059               18\n",
      "18           0.25           250         0.812570               19\n",
      "19           0.25           300         0.808081               20\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "# For this model, the learning_rate and n_estimators parameters \n",
    "parameters = {'learning_rate': [0.1, 0.15, 0.2, 0.25], \n",
    "              'n_estimators': [100, 150, 200, 250, 300]}\n",
    "grid_search = GridSearchCV(model, parameters, cv=10)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "# View grid search results\n",
    "df = grid_search_results(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction and cv score\n",
    "cv_accuracy['Gradient Boosting Classifer'] = df['mean_test_score'].max() * 100\n",
    "predictions['Gradient Boosting Classifer'] = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gradient Boosting Classifer    83.726150\n",
       "Random Forest                  81.705948\n",
       "Logistic Regression            79.687436\n",
       "Linear SVC                     78.339065\n",
       "Gaussian Naive Bayes           78.246737\n",
       "Decision Tree                  78.230451\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_accuracy.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-validation scores indicate the Gradient Boosting Classifier has outperformed the other methods by more than one percentage point. CV scores however, don't always apply to the test scores. In fact, logistic regression got the best score out of these methods, with 79.904% accuracy, placing at the top 16% at the time of submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
